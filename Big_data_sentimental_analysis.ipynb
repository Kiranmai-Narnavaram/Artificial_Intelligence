{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Big-data-sentimental-analysis",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsXnRpHzWPD/WdstKmoMHe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kiranmai-Narnavaram/Artificial_Intelligence/blob/main/Big_data_sentimental_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "206o9kjVNjFY"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark==3.1.2 spark-nlp findspark kaggle nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.types import StringType, IntegerType\n",
        "\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.functions import col, to_timestamp, expr\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *"
      ],
      "metadata": {
        "id": "8mcmTuhHOAhd"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "import findspark"
      ],
      "metadata": {
        "id": "2dW3A2A6OHQ6"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "_0wdkq3yOPSd"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "os.environ['SPARK_HOME'] = '/content/spark-3.1.2-bin-hadoop3.2'\n",
        "\n",
        "findspark.init('spark-3.1.2-bin-hadoop3.2')"
      ],
      "metadata": {
        "id": "t1OPW6NarfYr"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark"
      ],
      "metadata": {
        "id": "bCAfCXsOrl0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName('Spark NLP')\\\n",
        "    .master('local[*]')\\\n",
        "    .config('spark.driver.memory','16G')\\\n",
        "    .config('spark.driver.maxResultSize', '0') \\\n",
        "    .config('spark.kryoserializer.buffer.max', '2000M')\\\n",
        "    .config('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.12:3.4.1')\\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "v6T2PvxIrvk1"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df =(spark.read\n",
        "          .format('csv')\n",
        "          .option('header', 'false')\n",
        "          .load('training.1600000.processed.noemoticon.csv'))\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "id": "ieIhWgX3r5uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.count(), len(df.columns)"
      ],
      "metadata": {
        "id": "v-r3Oy2ksc3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "YgUSY1ogtEl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = (df.withColumnRenamed('_c0','target')\n",
        "        .withColumnRenamed('_c1','id')\n",
        "        .withColumnRenamed('_c2','tweet_date')\n",
        "        .withColumnRenamed('_c3','flag')\n",
        "        .withColumnRenamed('_c4','user')\n",
        "        .withColumnRenamed('_c5','text')\n",
        ")\n",
        "\n",
        "df = df.withColumn('tweet_date', expr('substring(tweet_date, 5, 27)'))\n",
        "\n",
        "\n",
        "df = df.select(col('target').cast('int'),\n",
        "                         col('id').cast('int'),\n",
        "                         to_timestamp(col('tweet_date'),'MMM dd HH:mm:ss zzz yyyy').alias('date'),\n",
        "                         col('flag').cast('string'),\n",
        "                         col('user').cast('string'),\n",
        "                         col('text').cast('string'),\n",
        "                        )"
      ],
      "metadata": {
        "id": "YZ8iGqC7tMSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('weekday', f.date_format('date', 'EEEE'))"
      ],
      "metadata": {
        "id": "LehqpfTStQ16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "SXN5iwzhtT9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "qoqz8rWvtcRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "dataset = df.sample(0.10).toPandas()"
      ],
      "metadata": {
        "id": "VGH3TA5Mu2na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = dataset['target'].value_counts().keys().tolist()\n",
        "counts = dataset['target'].value_counts().tolist()\n",
        "\n",
        "fig = px.pie(values=counts, names=['Postitive','Negative'], title='Feedback distribuition')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "l_7ZXEhmu45A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(dataset, y='text', x='weekday', color='target', labels=['Positive','Negative'], barmode='group', histfunc='count', height=400 )\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bmDsmjPGvWZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP "
      ],
      "metadata": {
        "id": "io0bWpuHvdDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "k0p6EO4tvgnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "id": "gRmaXvvvvoEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "@udf(returnType=StringType()) \n",
        "def clean_tweet(tweet):\n",
        " \n",
        "  word_tokens = word_tokenize(tweet)\n",
        "  \n",
        "  filtered_sentence = [w.lower() for w in word_tokens if not w.lower() in stop_words and w.isalpha()]\n",
        "\n",
        "  return ' '.join(filtered_sentence)"
      ],
      "metadata": {
        "id": "e59VxwoTvsIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('clean_text', clean_tweet(col('text')))\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "id": "G43tQ8TRvxJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_df = df.select(col('clean_text'), col('target'))\n",
        "\n",
        "end_df.show()"
      ],
      "metadata": {
        "id": "H05hn4gmv8Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Model"
      ],
      "metadata": {
        "id": "1vD1O3SjwBJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "Y2cZIm3KwGrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "    .setInputCol('clean_text')\\\n",
        "    .setOutputCol('document')\n",
        "    \n",
        "use = UniversalSentenceEncoder.pretrained(name='tfhub_use', lang='en')\\\n",
        " .setInputCols(['document'])\\\n",
        " .setOutputCol('sentence_embeddings')\n",
        "\n",
        "sentiment_dl = SentimentDLModel.pretrained(name='sentimentdl_use_twitter', lang='en')\\\n",
        "    .setInputCols(['sentence_embeddings'])\\\n",
        "    .setOutputCol('sentiment')"
      ],
      "metadata": {
        "id": "a78Y_SXtwKAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(\n",
        "      stages = [\n",
        "          document_assembler,\n",
        "          use,\n",
        "          sentiment_dl\n",
        "      ])"
      ],
      "metadata": {
        "id": "a28Yi7sbwf9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training for the model"
      ],
      "metadata": {
        "id": "rrVvkoVTwjxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(training_data, test_data) = end_df.randomSplit([0.75, 0.25])\n",
        "model = pipeline.fit(training_data)"
      ],
      "metadata": {
        "id": "6w_59SGWwqgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transform(test_data)\n",
        "result.show(20)"
      ],
      "metadata": {
        "id": "JDjMYYpDwvHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_result = result.withColumn('cols', f.explode(f.arrays_zip('document.result', 'sentiment.result'))) \\\n",
        ".select(f.expr(\"cols['0']\").alias('document'), 'target', \n",
        "        f.expr(\"cols['1']\").alias('sentiment'))\n",
        "\n",
        "sentiment_result.show(truncate=False)"
      ],
      "metadata": {
        "id": "NLRQlfSqzGnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model\n"
      ],
      "metadata": {
        "id": "ZYRnraxpyJqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RESULT_MAP = { 'positive': 4, 'negative':0, 'neutral':2 }\n",
        "\n",
        "@udf(returnType=IntegerType())\n",
        "def map_results(text):\n",
        "  return RESULT_MAP[text]"
      ],
      "metadata": {
        "id": "Pl76yXLt3IAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_result = sentiment_result.na.drop()\n",
        "\n",
        "final_result = sentiment_result.withColumn('result', map_results(col('sentiment')))\n",
        "\n",
        "final_result.show()"
      ],
      "metadata": {
        "id": "6VJRxZmz3K98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictionAndLabels = final_result.select('target', 'result')\n",
        "metrics = MulticlassMetrics(predictionAndLabels.rdd.map(lambda x: tuple(map(float, x))))"
      ],
      "metadata": {
        "id": "8UpQgczR31ww"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}